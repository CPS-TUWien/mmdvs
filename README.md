# MMDVS-LF

<p align="center">
    <img src="/images/recording_scheme.png" width="600">
</p>

Dynamic Vision Sensors (DVS) offer a unique advantage in control applications due to their high temporal resolution and asynchronous event-based data. Still, their adoption in machine learning algorithms remains limited. To address this gap and promote the development of models that leverage the specific characteristics of DVS data, we introduce the MMDVS-LF: Multi-Modal Dynamic Vision Sensor and Eye-Tracking Dataset for Line Following. This comprehensive dataset is the first to integrate multiple sensor modalities, including DVS recordings and eye-tracking data from a small-scale standardized vehicle. Additionally, the dataset includes RGB video, odometry, Inertial Measurement Unit (IMU) data, and demographic data of drivers performing a Line Following. With its diverse range of data, MMDVS-LF opens new opportunities for developing event-based deep learning algorithms just like the MNIST dataset did for Convolutional Neural Networks.

## MMDVS-LF: Multi-Modal Dynamic Vision Sensor and Eye-Tracking Dataset for Line Following

### Training Setup
<p align="center">
    <img src="/images/model_architecture.png" width="600">
</p>

## Citation
```bibtex
@misc{resch2024mmdvslfmultimodaldynamicvisionsensorline,
      title={MMDVS-LF: A Multi-Modal Dynamic-Vision-Sensor Line Following Dataset}, 
      author={Felix Resch and MÃ³nika Farsang and Radu Grosu},
      year={2024},
      eprint={2409.18038},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2409.18038}, 
}
```
